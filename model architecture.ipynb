{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(folder):\n",
    "    data_files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    data_file=data_files[random.randint(0,len(data_files)-1)]\n",
    "    with open(f'data//{data_file}','rb') as f:\n",
    "        data=pickle.load(f)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(len(data)):\n",
    "        x.append(data[i][0])\n",
    "        y.append(data[i][1])\n",
    "    x=torch.from_numpy(x).to(torch.float32)\n",
    "    y=torch.from_numpy(y).to(torch.long)\n",
    "    return x,y\n",
    "x_train,y_train=get_data('data')\n",
    "x_test,y_test=get_data('test_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a skip connection network\n",
    "\n",
    "device='cuda'\n",
    "class Block(nn.Module):\n",
    "    expansion=4\n",
    "    def __init__(self,in_channels,out_channels,downsample=None,stride=1):\n",
    "        super(Block,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_channels)\n",
    "        self.conv2=nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(out_channels)\n",
    "        self.conv3=nn.Conv2d(out_channels,out_channels*Block.expansion,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.bn3=nn.BatchNorm2d(out_channels*Block.expansion)\n",
    "        self.downsample=downsample\n",
    "    def forward(self,x):\n",
    "        identity=x\n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=F.relu(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=F.relu(out)\n",
    "        out=self.conv3(out)\n",
    "        out=self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            identity=self.downsample(identity)\n",
    "        out+=identity\n",
    "        out=F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,layers,output_size):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channels=64\n",
    "        self.conv1=nn.Conv2d(1,self.in_channels,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1= nn.BatchNorm2d(self.in_channels)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)   \n",
    "\n",
    "        #Define Block layers\n",
    "        self.layer1=self._make_layer(layers[0],64,1)\n",
    "        self.layer2=self._make_layer(layers[1],128,2)\n",
    "        self.layer3=self._make_layer(layers[2],256,2)\n",
    "        self.layer4=self._make_layer(layers[3],512,2)\n",
    "\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.fc=nn.Linear(64*Block.expansion,output_size)\n",
    "\n",
    "    def _make_layer(self,num_blocks,out_channels,stride=1):\n",
    "        downsample=None\n",
    "        if stride!=1 or self.in_channels!=out_channels*Block.expansion:\n",
    "            downsample=nn.Sequential(nn.Conv2d(self.in_channels,out_channels*Block.expansion,kernel_size=1,stride=stride,padding=0,bias=False),\n",
    "                                     nn.BatchNorm2d(out_channels*Block.expansion))\n",
    "        layers=[]\n",
    "        layers.append(Block(in_channels=self.in_channels,out_channels=out_channels,downsample=downsample,stride=stride))\n",
    "        self.in_channels=out_channels*Block.expansion\n",
    "        for _ in range(num_blocks-1):\n",
    "            layers.append(Block(in_channels=self.in_channels,out_channels=out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, inputs):\n",
    "        inputs=inputs.to(device)\n",
    "        out=self.conv1(inputs)\n",
    "        \n",
    "        out=self.bn1(out)\n",
    "        out=self.maxpool1(out)\n",
    "        out=self.layer1(out)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        out=self.layer4(out)\n",
    "        out=self.avgpool(out)\n",
    "        out=torch.flatten(out,1)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "\n",
    "layers=[3,4,6,3]\n",
    "output_size=200\n",
    "model=ResNet(layers,output_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    BATCH_SIZE=500\n",
    "    predictions=torch.tensor([])\n",
    "    for i in range(0,len(x),BATCH_SIZE):\n",
    "        y_hat=model(x[i:i+BATCH_SIZE]).to('cpu')\n",
    "        _,pred=torch.max(y_hat,1)\n",
    "        predictions=torch.cat((predictions,pred),dim=0)\n",
    "    return predictions.to(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "MINI_BATCH_SIZE=32\n",
    "accumalation_step=1\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.adam(model.parameters(),lr=1e-2)\n",
    "\n",
    "\n",
    "train_loss_progress=[]\n",
    "train_loss_hist=[]\n",
    "val_loss_hist=[]\n",
    "\n",
    "training_accuracy_hist=[]\n",
    "val_accuracy_hist=[]\n",
    "for epoch in range(EPOCHS):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(x_test[:200]).to('cpu')\n",
    "    loss_val= loss_fn(y_hat,y_test[:200])\n",
    "    predictions=get_predictions(x_test)\n",
    "    val_acc=accuracy_score(y_test.numpy(), predictions.numpy())\n",
    "    val_accuracy_hist.append(val_acc)\n",
    "    print(val_acc)\n",
    "\n",
    "    predictions=get_predictions(x_train)\n",
    "    training_accuracy_hist.append(accuracy_score(y_train.numpy(), predictions.numpy()))\n",
    "\n",
    "    model.train()\n",
    "    for i in range(0,len(x_train),MINI_BATCH_SIZE):\n",
    "        y_hat=model(x_train[i:i+MINI_BATCH_SIZE]).to('cpu')\n",
    "        loss=loss_fn(y_hat,y_train[i:i+MINI_BATCH_SIZE])\n",
    "        loss=loss/accumalation_step\n",
    "        loss.backward()\n",
    "        if (i+1)% accumalation_step==0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    x_train,y_train=get_data('data')\n",
    "    x_test,y_test=get_data('test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_loss_hist, label='List 1',color='blue')\n",
    "# plt.plot(val_loss_hist, label='List 2',color='red')\n",
    "# plt.show()\n",
    "plt.plot(training_accuracy_hist[0:], label='List 1',color='blue')\n",
    "plt.plot(val_accuracy_hist[0:], label='List 2',color='red')\n",
    "plt.show()\n",
    "model.eval()\n",
    "predictions=get_predictions(x_test)\n",
    "report = classification_report(y_test.numpy(), predictions.numpy(), target_names=[str(i) for i in range(200)])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
